{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795d6a1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "\n",
    "# load the data\n",
    "df=pd.read_csv('train.csv')\n",
    "dft=pd.read_csv('test.csv')\n",
    "dfs = pd.read_csv('sample_submission.csv')\n",
    "df=pd.concat([df, dft], axis=0)\n",
    "df = df.replace(np.nan,'0')\n",
    "\n",
    "df['text'] = df[['text', 'keyword']].agg(''.join, axis=1)\n",
    "\n",
    "# remove punctuation\n",
    "punc=[\n",
    "    '?','#','!','@','#','$','%','^','&','*',\n",
    "    '(',')','_','+','=','-','<','>',',','.',\n",
    "     ]\n",
    "     \n",
    "# for p in punc:\n",
    "#       df['text'] = df.apply(lambda x:x['text'].replace(p,'')  , axis=1)\n",
    "for p in punc:\n",
    "    df=df.replace(p,'')\n",
    "# tokkening\n",
    "\n",
    "df['text'] = df.apply(lambda row:nltk.word_tokenize(row['text'] ) , axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb60d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Use English stemmer.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# stemming\n",
    "df['text'] = df['text'].apply(lambda x: [stemmer.stem(y) for y in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae96ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer\n",
    "vocab= []\n",
    "for sentence in df['text']:\n",
    "    for word in sentence:\n",
    "         if word not in vocab:\n",
    "            vocab.append(word)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8743e90f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Index dictionary to assign an index to each word in vocabulary\n",
    "index_word = {}\n",
    "i = 0\n",
    "for word in vocab:\n",
    "    index_word[word] = i \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7feba9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#number of words in the vocab\n",
    "len_vector = len(vocab)\n",
    "def bag_of_words(sent):\n",
    "    count_dict = defaultdict(int)\n",
    "    vec = np.zeros(len_vector)\n",
    "    for item in sent:\n",
    "        count_dict[item] += 1\n",
    "    for key,item in count_dict.items():\n",
    "        vec[index_word[key]] = item\n",
    "    return vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a147125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.apply(lambda row:bag_of_words(row['text'] ) , axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8430d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword'] = df.apply(lambda row:bag_of_words(row['keyword'] ) , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37840bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='location')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abce6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['text'] = df.apply(lambda row:np.concatenate((np.array(row['text']), np.array(row['keyword'])))  , axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d129dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=['target','keyword'])\n",
    "df_1=x.iloc[0:7613,:]\n",
    "df_2=x.iloc[7613:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23660b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "arr_1=df_1['text'].to_numpy()\n",
    "sarr_1=np.stack( arr_1, axis=0 )\n",
    "a=sparse.csr_matrix(sarr_1)\n",
    "\n",
    "arr_2=df_2['text'].to_numpy()\n",
    "sarr_2=np.stack( arr_2, axis=0 )\n",
    "b=sparse.csr_matrix(sarr_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df7d695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.RidgeClassifier()\n",
    "tar=pd.read_csv('train.csv')\n",
    "clf.fit(a, tar[\"target\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be330cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['target']= clf.predict(b)\n",
    "dfs.set_index('id', inplace=True)\n",
    "\n",
    "dfs.to_csv('prediction_results_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d11ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
